{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 경고창 제거\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='Malgun Gothic') # 폰트 지정\n",
    "plt.rc('axes', unicode_minus=False) # 마이너스 폰트 설정\n",
    "%config InlineBackend.figure_format='retina' # 그래프 글씨 뚜렷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시장베이시스</th>\n",
       "      <th>이론베이시스</th>\n",
       "      <th>괴리율</th>\n",
       "      <th>원위안 야간변동율</th>\n",
       "      <th>원엔 야간변동율</th>\n",
       "      <th>KOSPI 전날변동율</th>\n",
       "      <th>KOSPI 야간변동율</th>\n",
       "      <th>KS200 전날변동율</th>\n",
       "      <th>KS200 야간변동율</th>\n",
       "      <th>NAS 야간변동율</th>\n",
       "      <th>...</th>\n",
       "      <th>원달러 야간변동율</th>\n",
       "      <th>VIX 전날변동율</th>\n",
       "      <th>VIX 당일변동율</th>\n",
       "      <th>VIX 당일변화량</th>\n",
       "      <th>JNIV 종가변동율</th>\n",
       "      <th>JNIV 전날변동율</th>\n",
       "      <th>JNIV 전날변화량</th>\n",
       "      <th>CD 전날변동율</th>\n",
       "      <th>CD 전날변화량</th>\n",
       "      <th>VKOSPI_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-10</th>\n",
       "      <td>1.56</td>\n",
       "      <td>2.31</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.156</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.264</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086</td>\n",
       "      <td>1.43</td>\n",
       "      <td>-9.417</td>\n",
       "      <td>2.04</td>\n",
       "      <td>-8.44</td>\n",
       "      <td>1.214</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-11</th>\n",
       "      <td>2.34</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>1.413</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.520</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-3.79</td>\n",
       "      <td>-3.785</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>-1.964</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-12</th>\n",
       "      <td>2.26</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.617</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-5.52</td>\n",
       "      <td>-5.074</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.983</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-13</th>\n",
       "      <td>1.60</td>\n",
       "      <td>2.17</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.036</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.794</td>\n",
       "      <td>2.64</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>1.423</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-16</th>\n",
       "      <td>2.08</td>\n",
       "      <td>2.11</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.513</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064</td>\n",
       "      <td>15.76</td>\n",
       "      <td>16.878</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            시장베이시스  이론베이시스   괴리율  원위안 야간변동율  원엔 야간변동율  KOSPI 전날변동율  \\\n",
       "2023-10-10    1.56    2.31 -0.23      0.070     0.056         0.21   \n",
       "2023-10-11    2.34    2.17  0.05      0.109     0.105        -0.26   \n",
       "2023-10-12    2.26    2.18  0.02      0.093     0.105         1.98   \n",
       "2023-10-13    1.60    2.17 -0.17      0.043     0.036         1.21   \n",
       "2023-10-16    2.08    2.11 -0.01      0.081     0.124        -0.95   \n",
       "\n",
       "            KOSPI 야간변동율  KS200 전날변동율  KS200 야간변동율  NAS 야간변동율  ...  원달러 야간변동율  \\\n",
       "2023-10-10        1.156         0.11        1.264       0.39  ...      0.086   \n",
       "2023-10-11        1.413         0.05        1.520       0.58  ...      0.096   \n",
       "2023-10-12        0.617         1.76        0.662       0.71  ...      0.084   \n",
       "2023-10-13       -0.765         1.27       -0.833      -0.63  ...      0.033   \n",
       "2023-10-16       -0.559        -0.94       -0.513      -1.23  ...      0.064   \n",
       "\n",
       "            VIX 전날변동율  VIX 당일변동율  VIX 당일변화량  JNIV 종가변동율  JNIV 전날변동율  \\\n",
       "2023-10-10       1.43     -9.417       2.04       -8.44       1.214   \n",
       "2023-10-11      -3.79     -3.785       1.35       -1.78      -1.964   \n",
       "2023-10-12      -5.52     -5.074       1.69        3.03       1.983   \n",
       "2023-10-13       3.73      3.794       2.64       -1.99       1.423   \n",
       "2023-10-16      15.76     16.878       4.28        0.05       0.878   \n",
       "\n",
       "            JNIV 전날변화량  CD 전날변동율  CD 전날변화량  VKOSPI_Label  \n",
       "2023-10-10        0.76    -0.261      0.01             1  \n",
       "2023-10-11        0.92     0.000      0.00             0  \n",
       "2023-10-12        0.69     0.000      0.00             0  \n",
       "2023-10-13        0.86     0.000      0.00             0  \n",
       "2023-10-16        0.93     0.000      0.00             1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../model_dataset/half_features.csv',index_col=0)\n",
    "train_df.head()\n",
    "test_df = pd.read_csv(\"../model_dataset/test_features.csv\",index_col=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test셋 분리\n",
    "X_train = train_df.drop(columns='VKOSPI_Label',axis=1)\n",
    "y_train = train_df[['VKOSPI_Label']]\n",
    "X_val = test_df.drop(columns='VKOSPI_Label',axis=1)\n",
    "y_val = test_df[['VKOSPI_Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling 진행\n",
    "* Standard\n",
    "* Minmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 표준화\n",
    "# features_to_standardize = ['시장베이시스', '이론베이시스', '괴리율', '원위안 야간변동율', '원엔 야간변동율', 'KOSPI 전날변동율',\n",
    "#        'KOSPI 야간변동율', 'KS200 전날변동율', 'KS200 야간변동율', 'NAS 야간변동율', 'NAS 당일변동율',\n",
    "#        'NAS 당일변화량', 'P/C Ratio', 'CALL_vol_change(%)', 'PUT_vol_change(%)',\n",
    "#        'CALL_vol_fluc', 'PUT_vol_fluc', 'S&P 야간변동율', 'S&P 당일변동율', 'S&P 당일변화량',\n",
    "#        '원달러 야간변동율', 'VIX 전날변동율', 'VIX 당일변동율', 'VIX 당일변화량', 'JNIV 종가변동율',\n",
    "#        'JNIV 전날변동율', 'JNIV 전날변화량', 'CD 전날변동율', 'CD 전날변화량']\n",
    "# scaler_standardize = StandardScaler()\n",
    "# X_train = scaler_standardize.fit_transform(X_train[features_to_standardize])\n",
    "# X_val = scaler_standardize.transform(X_val[features_to_standardize])\n",
    "\n",
    "# X_train = pd.DataFrame(X_train, columns=features_to_standardize)\n",
    "# X_val = pd.DataFrame(X_val, columns=features_to_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax 스케일링\n",
    "\n",
    "features_to_minmax = ['시장베이시스', '이론베이시스', '괴리율', '원위안 야간변동율', '원엔 야간변동율', 'KOSPI 전날변동율',\n",
    "       'KOSPI 야간변동율', 'KS200 전날변동율', 'KS200 야간변동율', 'NAS 야간변동율', 'NAS 당일변동율',\n",
    "       'NAS 당일변화량', 'P/C Ratio', 'CALL_vol_change(%)', 'PUT_vol_change(%)',\n",
    "       'CALL_vol_fluc', 'PUT_vol_fluc', 'S&P 야간변동율', 'S&P 당일변동율', 'S&P 당일변화량',\n",
    "       '원달러 야간변동율', 'VIX 전날변동율', 'VIX 당일변동율', 'VIX 당일변화량', 'JNIV 종가변동율',\n",
    "       'JNIV 전날변동율', 'JNIV 전날변화량', 'CD 전날변동율', 'CD 전날변화량']\n",
    "\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_train = scaler_minmax.fit_transform(X_train[features_to_minmax])\n",
    "X_val = scaler_minmax.transform(X_val[features_to_minmax])\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=features_to_minmax)\n",
    "X_val = pd.DataFrame(X_val, columns=features_to_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF 기반 feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature_Importances\n",
    "\n",
    "# rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# rfc.fit(X_train, y_train)\n",
    "\n",
    "# rfc.feature_importances_\n",
    "\n",
    "# ftr_importances = pd.Series(rfc.feature_importances_, index=X_train.columns)\n",
    "# sorted_feature_importance = ftr_importances.sort_values(ascending=True)\n",
    "\n",
    "# data = sorted_feature_importance\n",
    "# importance = pd.DataFrame(data, columns=['feature importances'])\n",
    "# importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# colors = plt.cm.tab20(np.linspace(0, 1, len(importance)))\n",
    "\n",
    "# plt.barh(importance.index, importance['feature importances'], color=colors)  # Changed to barh for horizontal bar chart\n",
    "# plt.ylabel('Features')  # Changed to 'Features' for Y-axis label\n",
    "# plt.xlabel('Importance')  # Changed to 'Importance' for X-axis label\n",
    "# plt.title('Feature Importances')\n",
    "\n",
    "# # Rotating x labels for better visibility if needed\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit기반 피쳐 갯수 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "\n",
    "logit = SelectFromModel(LogisticRegression())\n",
    "logit.fit(X_train, y_train)\n",
    "logit_support = logit.get_support()\n",
    "lr_feature = X_train.loc[:,logit_support].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이론베이시스', '원위안 야간변동율', 'NAS 야간변동율', 'NAS 당일변동율', 'NAS 당일변화량', 'PUT_vol_change(%)', 'S&P 야간변동율', 'S&P 당일변화량', 'VIX 전날변동율', 'VIX 당일변동율', 'VIX 당일변화량', 'JNIV 종가변동율', 'JNIV 전날변화량']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(lr_feature)\n",
    "print(len(lr_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_feature=['이론베이시스','원위안 야간변동율', 'NAS 당일변동율', 'PUT_vol_change(%)', \n",
    "'S&P 야간변동율', 'S&P 당일변화량','VIX 당일변동율', 'VIX 당일변화량', 'JNIV 종가변동율', 'JNIV 전날변화량']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.300579</td>\n",
       "      <td>NAS 당일변동율</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.398001</td>\n",
       "      <td>S&amp;P 야간변동율</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.678374</td>\n",
       "      <td>VIX 당일변동율</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.660854</td>\n",
       "      <td>VIX 당일변화량</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.496398</td>\n",
       "      <td>원위안 야간변동율</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.839102</td>\n",
       "      <td>PUT_vol_change(%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.674116</td>\n",
       "      <td>S&amp;P 당일변화량</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.501163</td>\n",
       "      <td>JNIV 종가변동율</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.209386</td>\n",
       "      <td>이론베이시스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.983946</td>\n",
       "      <td>JNIV 전날변화량</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF Factor           features\n",
       "0   28.300579          NAS 당일변동율\n",
       "1   21.398001          S&P 야간변동율\n",
       "2    7.678374          VIX 당일변동율\n",
       "3    7.660854          VIX 당일변화량\n",
       "4    7.496398          원위안 야간변동율\n",
       "5    6.839102  PUT_vol_change(%)\n",
       "6    6.674116          S&P 당일변화량\n",
       "7    5.501163         JNIV 종가변동율\n",
       "8    4.209386             이론베이시스\n",
       "9    2.983946         JNIV 전날변화량"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vif(data):\n",
    "    import pandas as pd\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "    # VIF 출력을 위한 데이터 프레임 형성\n",
    "    vif = pd.DataFrame()\n",
    "\n",
    "    # VIF 값과 각 Feature 이름에 대해 설정\n",
    "    vif[\"VIF Factor\"] = [variance_inflation_factor(data.values, i) for i in range(len(data.columns))]\n",
    "    vif[\"features\"] = data.columns \n",
    "                    \n",
    "    # VIF 값이 높은 순으로 정렬\n",
    "    vif = vif.sort_values(by=\"VIF Factor\", ascending=False)\n",
    "    vif = vif.reset_index().drop(columns='index')\n",
    "    \n",
    "    return vif\n",
    "\n",
    "vif(X_train[lr_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm = LGBMClassifier()\n",
    "# lgbm.fit(X_train, y_train)\n",
    "# lda_pred = lgbm.predict(X_val)\n",
    "# lda_pred_proba = lgbm.predict_proba(X_val)\n",
    "\n",
    "# get_clf_eval(y_val, lda_pred)\n",
    "# get_eval_by_threshold(y_val , lda_pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wrapper : 모델링을 돌리면서 변수를 선택하는 방법\n",
    "\n",
    "- Forward Selection(전진 선택) : 변수가 없는 상태로 시작하며 반복할 때마다 가장 중요한 변수를 추가하여 더 이상 성능의 향상이 없을 때까지 변수를 추가한다.\n",
    "- Backward Elimination(후방 제거) : 모든 변수를 가지고 시작하며, 가장 덜 중요한 변수를 하나씩 제거하면서 모델의 성능을 향상시킨다. 더 이상 성능의 향상이 없을 때까지 반복한다.\n",
    "- Stepwise Selection(단계별 선택): Foward Selection 과 Backward Elimination 을 결합하여 사용하는 방식으로, 모든  변수를 가지고 시작하여 가장 도움이 되지 않는 변수를 삭제하거나, 모델에서 빠져있는 변수 중에서 가장 중요한 변수를 추가하는 방법이다. 이와 같이 변수를 추가 또는 삭제를 반복한다. 반대로 아무것도 없는 모델에서 출발해 변수를 추가, 삭제를 반복할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward Selection\n",
    "# import pandas as pd\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Forward feature selection 수행\n",
    "# selected_features = []\n",
    "# best_score = 0\n",
    "\n",
    "# while len(selected_features) < train_df.shape[1]:\n",
    "#     best_feature = None\n",
    "#     best_model = None\n",
    "#     best_score_local = 0\n",
    "\n",
    "#     for feature in X_train.columns:\n",
    "#         if feature not in selected_features:\n",
    "#             features = selected_features + [feature]\n",
    "#             X_train_selected = X_train[features]\n",
    "#             X_val_selected = X_val[features]\n",
    "\n",
    "#             model = LogisticRegression()\n",
    "#             model.fit(X_train_selected, y_train)\n",
    "#             score = model.score(X_val_selected, y_val)\n",
    "\n",
    "#             if score > best_score_local:\n",
    "#                 best_score_local = score\n",
    "#                 best_feature = feature\n",
    "#                 best_model = model\n",
    "\n",
    "#     if best_score_local > best_score:\n",
    "#         selected_features.append(best_feature)\n",
    "#         best_score = best_score_local\n",
    "#         print(f\"Selected feature: {best_feature}, Accuracy: {best_score:.4f}\")\n",
    "\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# print(\"\\nForward selected features:\")\n",
    "# Forward = selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Backward Elimination\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Backward feature selection 수행\n",
    "# selected_features = X_train.columns.tolist()\n",
    "# best_score = 0\n",
    "\n",
    "# while len(selected_features) > 0:\n",
    "#     worst_feature = None\n",
    "#     best_model = None\n",
    "#     best_score_local = 0\n",
    "\n",
    "#     for feature in selected_features:\n",
    "#         features = selected_features.copy()\n",
    "#         features.remove(feature)\n",
    "\n",
    "#         X_train_selected = X_train[features]\n",
    "#         X_val_selected = X_val[features]\n",
    "\n",
    "#         model = LogisticRegression()\n",
    "#         model.fit(X_train_selected, y_train)\n",
    "#         score = model.score(X_val_selected, y_val)\n",
    "\n",
    "#         if score > best_score_local:\n",
    "#             best_score_local = score\n",
    "#             worst_feature = feature\n",
    "#             best_model = model\n",
    "\n",
    "#     if best_score_local > best_score:\n",
    "#         selected_features.remove(worst_feature)\n",
    "#         best_score = best_score_local\n",
    "#         print(f\"Removed feature: {worst_feature}, Accuracy: {best_score:.4f}\")\n",
    "\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# print(\"\\nFinal selected features:\")\n",
    "# Backward = selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stepwise Selection\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Stepwise feature selection 수행\n",
    "# selected_features = []\n",
    "# best_score = 0\n",
    "\n",
    "# # Forward step\n",
    "# while len(selected_features) < train_df.shape[1]:\n",
    "#     best_feature = None\n",
    "#     best_model = None\n",
    "#     best_score_local = 0\n",
    "\n",
    "#     for feature in X_train.columns:\n",
    "#         if feature not in selected_features:\n",
    "#             features = selected_features + [feature]\n",
    "#             X_train_selected = X_train[features]\n",
    "#             X_val_selected = X_val[features]\n",
    "\n",
    "#             model = LogisticRegression()\n",
    "#             model.fit(X_train_selected, y_train)\n",
    "#             score = model.score(X_val_selected, y_val)\n",
    "\n",
    "#             if score > best_score_local:\n",
    "#                 best_score_local = score\n",
    "#                 best_feature = feature\n",
    "#                 best_model = model\n",
    "\n",
    "#     if best_score_local > best_score:\n",
    "#         selected_features.append(best_feature)\n",
    "#         best_score = best_score_local\n",
    "#         print(f\"Selected feature: {best_feature}, Accuracy: {best_score:.4f}\")\n",
    "\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# # Backward step\n",
    "# while len(selected_features) > 0:\n",
    "#     worst_feature = None\n",
    "#     best_model = None\n",
    "#     best_score_local = 0\n",
    "\n",
    "#     for feature in selected_features:\n",
    "#         features = selected_features.copy()\n",
    "#         features.remove(feature)\n",
    "\n",
    "#         X_train_selected = X_train[features]\n",
    "#         X_val_selected = X_val[features]\n",
    "\n",
    "#         model = LogisticRegression()\n",
    "#         model.fit(X_train_selected, y_train)\n",
    "#         score = model.score(X_val_selected, y_val)\n",
    "\n",
    "#         if score > best_score_local:\n",
    "#             best_score_local = score\n",
    "#             worst_feature = feature\n",
    "#             best_model = model\n",
    "\n",
    "#     if best_score_local > best_score:\n",
    "#         selected_features.remove(worst_feature)\n",
    "#         best_score = best_score_local\n",
    "#         print(f\"Removed feature: {worst_feature}, Accuracy: {best_score:.4f}\")\n",
    "\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# print(\"\\nFinal selected features:\")\n",
    "# Stepwise = selected_features\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embedded\n",
    "- Lasso, Ridge, Elastic Net 등 내장함수 사용하여 변수를 선택하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "GridSearchCV 최고 정확도:0.7107\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "lasso_model = LogisticRegression()\n",
    "param_grid = {'penalty' : ['l1'], \n",
    "                'C' : [0.001, 0.01, 0.1, 1, 2, 5, 10],\n",
    "                'solver' : ['liblinear']}\n",
    "\n",
    "grid_search = GridSearchCV(lasso_model, param_grid=param_grid, return_train_score=True, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(grid_search.cv_results_)\n",
    "df = df.sort_values(by=['rank_test_score'], ascending=True)\n",
    "df[['params', 'mean_train_score', 'mean_test_score', 'rank_test_score']]\n",
    "print('GridSearchCV 최적 파라미터:', grid_search.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이론베이시스</td>\n",
       "      <td>0.718039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>괴리율</td>\n",
       "      <td>-0.362694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>원위안 야간변동율</td>\n",
       "      <td>-1.803673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NAS 야간변동율</td>\n",
       "      <td>-1.506502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NAS 당일변동율</td>\n",
       "      <td>2.101627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P/C Ratio</td>\n",
       "      <td>0.194980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PUT_vol_change(%)</td>\n",
       "      <td>-2.302137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CALL_vol_fluc</td>\n",
       "      <td>1.438149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>S&amp;P 야간변동율</td>\n",
       "      <td>-1.521572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S&amp;P 당일변화량</td>\n",
       "      <td>-1.251749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VIX 당일변동율</td>\n",
       "      <td>0.850980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VIX 당일변화량</td>\n",
       "      <td>0.627851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JNIV 종가변동율</td>\n",
       "      <td>1.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JNIV 전날변화량</td>\n",
       "      <td>-0.989498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CD 전날변화량</td>\n",
       "      <td>-1.071104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature      coef\n",
       "1              이론베이시스  0.718039\n",
       "2                 괴리율 -0.362694\n",
       "3           원위안 야간변동율 -1.803673\n",
       "9           NAS 야간변동율 -1.506502\n",
       "10          NAS 당일변동율  2.101627\n",
       "12          P/C Ratio  0.194980\n",
       "14  PUT_vol_change(%) -2.302137\n",
       "15      CALL_vol_fluc  1.438149\n",
       "17          S&P 야간변동율 -1.521572\n",
       "19          S&P 당일변화량 -1.251749\n",
       "22          VIX 당일변동율  0.850980\n",
       "23          VIX 당일변화량  0.627851\n",
       "24         JNIV 종가변동율  1.144600\n",
       "26         JNIV 전날변화량 -0.989498\n",
       "28           CD 전날변화량 -1.071104"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_best = LogisticRegression(C=5, penalty='l1', solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "df_lasso = pd.DataFrame()\n",
    "df_lasso['feature'] = X_train.columns\n",
    "df_lasso['coef'] = lasso_best.coef_[0]\n",
    "df_lasso.drop(df_lasso[df_lasso['coef']==0].index, inplace=True)\n",
    "df_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso에서 선택된 피처 수 15 개\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['이론베이시스',\n",
       " '괴리율',\n",
       " '원위안 야간변동율',\n",
       " 'NAS 야간변동율',\n",
       " 'NAS 당일변동율',\n",
       " 'P/C Ratio',\n",
       " 'PUT_vol_change(%)',\n",
       " 'CALL_vol_fluc',\n",
       " 'S&P 야간변동율',\n",
       " 'S&P 당일변화량',\n",
       " 'VIX 당일변동율',\n",
       " 'VIX 당일변화량',\n",
       " 'JNIV 종가변동율',\n",
       " 'JNIV 전날변화량',\n",
       " 'CD 전날변화량']"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라쏘에서 선택된 피처\n",
    "lasso = df_lasso['feature'].values.tolist()\n",
    "print('Lasso에서 선택된 피처 수 {0:1.0f}'.format(len(df_lasso)), '개')\n",
    "lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이전코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_Forward = list(Forward)\n",
    "# list_Backward = list(Backward)\n",
    "# list_Stepwise = list(Stepwise)\n",
    "# list_lasso = list(lasso)\n",
    "# list_col_all = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func_Forward(x):\n",
    "#     if x in list_Forward:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# def func_Backward(x):\n",
    "#     if x in list_Backward:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "\n",
    "# def func_Stepwise(x):\n",
    "#     if x in list_Stepwise:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "    \n",
    "# def func_lasso(x):\n",
    "#     if x in list_lasso:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Forward</th>\n",
       "      <th>Backward</th>\n",
       "      <th>Stepwise</th>\n",
       "      <th>lasso</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>시장베이시스</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KOSPI 야간변동율</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PUT_vol_change(%)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Forward  Backward  Stepwise  lasso  total\n",
       "0              시장베이시스        1         1         1      0      3\n",
       "6         KOSPI 야간변동율        1         1         1      0      3\n",
       "14  PUT_vol_change(%)        1         1         1      1      4"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 2번 선택된 Feature\n",
    "\n",
    "# feature_counts = pd.DataFrame()\n",
    "# feature_counts['Feature'] = list_col_all\n",
    "# feature_counts['Forward'] = list_col_all.map(func_Forward)\n",
    "# feature_counts['Backward'] = list_col_all.map(func_Backward)\n",
    "# feature_counts['Stepwise'] = list_col_all.map(func_Stepwise)\n",
    "# feature_counts['lasso'] = list_col_all.map(func_lasso)\n",
    "\n",
    "# feature_counts[\"total\"] = feature_counts[\"Forward\"]+feature_counts['Backward']+feature_counts['Stepwise']+feature_counts[\"lasso\"]\n",
    "# feature_final = feature_counts[feature_counts[\"total\"]>=2]\n",
    "# list_feature_final = list(feature_final[\"Feature\"])\n",
    "# print(\"선택된 피쳐수 :\", len(list_feature_final))\n",
    "feature_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(feature_final[['Feature']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3번 선택된 Feature\n",
    "\n",
    "# feature_counts = pd.DataFrame()\n",
    "# feature_counts['Feature'] = list_col_all\n",
    "# feature_counts['Forward'] = list_col_all.map(func_Forward)\n",
    "# feature_counts['Backward'] = list_col_all.map(func_Backward)\n",
    "# feature_counts['Stepwise'] = list_col_all.map(func_Stepwise)\n",
    "# feature_counts['lasso'] = list_col_all.map(func_lasso)\n",
    "\n",
    "# feature_counts[\"total\"] = feature_counts[\"Forward\"]+feature_counts['Backward']+feature_counts['Stepwise']+feature_counts[\"lasso\"]\n",
    "# feature_final = feature_counts[feature_counts[\"total\"]>=3]\n",
    "# list_feature_final = list(feature_final[\"Feature\"])\n",
    "# print(\"선택된 피쳐수 :\", len(list_feature_final))\n",
    "# feature_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[[ '이론베이시스','원위안 야간변동율', 'NAS 당일변동율', 'PUT_vol_change(%)', \n",
    "'S&P 야간변동율', 'S&P 당일변화량','VIX 당일변동율', 'VIX 당일변화량', 'JNIV 종가변동율', 'JNIV 전날변화량']]\n",
    "X_val = X_val[[ '이론베이시스','원위안 야간변동율', 'NAS 당일변동율', 'PUT_vol_change(%)', \n",
    "'S&P 야간변동율', 'S&P 당일변화량','VIX 당일변동율', 'VIX 당일변화량', 'JNIV 종가변동율', 'JNIV 전날변화량']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "def model_basic(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # ADASYN 오버샘플링을 적용합니다.\n",
    "    ada = ADASYN(sampling_strategy='minority', random_state=42)\n",
    "    X_train, y_train = ada.fit_resample(X_train, y_train)\n",
    "\n",
    "    models = [\n",
    "        LogisticRegression(),\n",
    "        DecisionTreeClassifier(),\n",
    "        SVC(),\n",
    "        RandomForestClassifier(),\n",
    "        XGBClassifier(),\n",
    "        LGBMClassifier()\n",
    "    ]\n",
    "\n",
    "    rdict={'model':[],'accuracy':[],'precision':[],'recall':[],'f1_score':[]}\n",
    "\n",
    "    \n",
    "    for clf in models:\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        results = (round(accuracy_score(y_test, pred),2),\n",
    "                    round(precision_score(y_test, pred),2),\n",
    "                    round(recall_score(y_test, pred),2),\n",
    "                    round(f1_score(y_test, pred),2))\n",
    "        rdict['model'].append(clf); \n",
    "        rdict['accuracy'].append(results[0])\n",
    "        rdict['precision'].append(results[1])\n",
    "        rdict['recall'].append(results[2])\n",
    "        rdict['f1_score'].append(results[3])\n",
    "\n",
    "        # print(results)\n",
    "\n",
    "    rdf = pd.DataFrame(data=rdict)\n",
    "    return rdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 88, number of negative: 86\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 560\n",
      "[LightGBM] [Info] Number of data points in the train set: 174, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505747 -> initscore=0.022990\n",
      "[LightGBM] [Info] Start training from score 0.022990\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBMClassifier()</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  precision  \\\n",
       "0                               LogisticRegression()      0.53       0.44   \n",
       "1                           DecisionTreeClassifier()      0.58       0.50   \n",
       "2                                              SVC()      0.47       0.38   \n",
       "3  (DecisionTreeClassifier(max_features='sqrt', r...      0.68       0.75   \n",
       "4  XGBClassifier(base_score=None, booster=None, c...      0.47       0.38   \n",
       "5                                   LGBMClassifier()      0.63       0.57   \n",
       "\n",
       "   recall  f1_score  \n",
       "0    0.50      0.47  \n",
       "1    0.38      0.43  \n",
       "2    0.38      0.38  \n",
       "3    0.38      0.50  \n",
       "4    0.38      0.38  \n",
       "5    0.50      0.53  "
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_basic(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def model_basic_with_gridsearch(X_train, y_train, X_val, y_val):\n",
    "    # 모델 및 해당 하이퍼파라미터 그리드 정의\n",
    "    models_and_grids = {\n",
    "        LogisticRegression(): {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.01, 0.1, 1, 10]\n",
    "        },\n",
    "        DecisionTreeClassifier(): {\n",
    "            'max_depth': [1,3,7,10],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "        SVC(): {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        },\n",
    "        RandomForestClassifier(): {\n",
    "            'n_estimators': [5,10,15,20],\n",
    "            'max_depth': [1,3,7,10],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        XGBClassifier(): {\n",
    "            'n_estimators': [5,10,15,20],\n",
    "            'learning_rate': [0.01, 0.1, 0.5]\n",
    "        },\n",
    "        LGBMClassifier(): {\n",
    "            'n_estimators': [5,10,15,20],\n",
    "            'learning_rate': [0.01, 0.1, 0.5]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    rdict = {'model': [], 'best_params': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1_score': []}\n",
    "\n",
    "    for model, grid in models_and_grids.items():\n",
    "        clf = GridSearchCV(model, grid, cv=5)\n",
    "        clf.fit(X_train, y_train)\n",
    "        best_model = clf.best_estimator_\n",
    "\n",
    "        pred = best_model.predict(X_val)\n",
    "        results = (round(accuracy_score(y_val, pred), 2),\n",
    "                   round(precision_score(y_val, pred, average='weighted'), 2),\n",
    "                   round(recall_score(y_val, pred, average='weighted'), 2),\n",
    "                   round(f1_score(y_val, pred, average='weighted'), 2))\n",
    "\n",
    "        rdict['model'].append(best_model.__class__.__name__)\n",
    "        rdict['best_params'].append(clf.best_params_)\n",
    "        rdict['accuracy'].append(results[0])\n",
    "        rdict['precision'].append(results[1])\n",
    "        rdict['recall'].append(results[2])\n",
    "        rdict['f1_score'].append(results[3])\n",
    "\n",
    "    rdf = pd.DataFrame(data=rdict)\n",
    "    return rdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 311\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 314\n",
      "[LightGBM] [Info] Number of data points in the train set: 97, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.288660 -> initscore=-0.901902\n",
      "[LightGBM] [Info] Start training from score -0.901902\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 35, number of negative: 86\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 121, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289256 -> initscore=-0.898999\n",
      "[LightGBM] [Info] Start training from score -0.898999\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 2, 'min_s...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 10, 'n_...</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 5}</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 5}</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                        best_params  \\\n",
       "0      LogisticRegression                       {'C': 0.01, 'penalty': 'l2'}   \n",
       "1  DecisionTreeClassifier  {'max_depth': 3, 'min_samples_leaf': 2, 'min_s...   \n",
       "2                     SVC                     {'C': 0.1, 'kernel': 'linear'}   \n",
       "3  RandomForestClassifier  {'max_depth': 10, 'min_samples_split': 10, 'n_...   \n",
       "4           XGBClassifier          {'learning_rate': 0.1, 'n_estimators': 5}   \n",
       "5          LGBMClassifier         {'learning_rate': 0.01, 'n_estimators': 5}   \n",
       "\n",
       "   accuracy  precision  recall  f1_score  \n",
       "0      0.58       0.34    0.58      0.42  \n",
       "1      0.68       0.70    0.68      0.66  \n",
       "2      0.58       0.34    0.58      0.42  \n",
       "3      0.74       0.82    0.74      0.70  \n",
       "4      0.58       0.34    0.58      0.42  \n",
       "5      0.58       0.34    0.58      0.42  "
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_basic_with_gridsearch(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능확인 코드\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "def get_clf_eval(MDA_y_test, pred):\n",
    "    confusion = confusion_matrix(MDA_y_test, pred)\n",
    "    accuracy = accuracy_score(MDA_y_test, pred)\n",
    "    precision = precision_score(MDA_y_test, pred)\n",
    "    recall = recall_score(MDA_y_test, pred)\n",
    "    roc_score = roc_auc_score(MDA_y_test, pred)\n",
    "    pr_score = average_precision_score(MDA_y_test, pred)\n",
    "    f1 = f1_score(MDA_y_test, pred)\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도 : {1:.4f}, 재현율:{2:.4f},F1 스코어:{3:.4f}'.format(accuracy, precision, recall, f1, roc_score))\n",
    "    print('ROC 스코어: {0:.4f}, PR score : {1:.4f}'.format(roc_score, pr_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값에 따른 오차행렬및 스코어 -------->#임계값 최적 : 재현율기준(0.1)/f1기준(0.3)\n",
    "from sklearn.preprocessing import Binarizer\n",
    "thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "\n",
    "def get_eval_by_threshold(MDA_y_test, pred_proba_c1, thresholds):\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print(\"임곗값:\", custom_threshold)\n",
    "        get_clf_eval(MDA_y_test, custom_predict)\n",
    "        print(\"---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[10  1]\n",
      " [ 4  4]]\n",
      "정확도: 0.7368, 정밀도 : 0.8000, 재현율:0.5000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.7045, PR score : 0.6105\n",
      "임곗값: 0.1\n",
      "오차행렬\n",
      "[[10  1]\n",
      " [ 4  4]]\n",
      "정확도: 0.7368, 정밀도 : 0.8000, 재현율:0.5000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.7045, PR score : 0.6105\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.2\n",
      "오차행렬\n",
      "[[10  1]\n",
      " [ 4  4]]\n",
      "정확도: 0.7368, 정밀도 : 0.8000, 재현율:0.5000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.7045, PR score : 0.6105\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.3\n",
      "오차행렬\n",
      "[[10  1]\n",
      " [ 4  4]]\n",
      "정확도: 0.7368, 정밀도 : 0.8000, 재현율:0.5000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.7045, PR score : 0.6105\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.4\n",
      "오차행렬\n",
      "[[10  1]\n",
      " [ 4  4]]\n",
      "정확도: 0.7368, 정밀도 : 0.8000, 재현율:0.5000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.7045, PR score : 0.6105\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[10  1]\n",
      " [ 4  4]]\n",
      "정확도: 0.7368, 정밀도 : 0.8000, 재현율:0.5000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.7045, PR score : 0.6105\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.6\n",
      "오차행렬\n",
      "[[10  1]\n",
      " [ 4  4]]\n",
      "정확도: 0.7368, 정밀도 : 0.8000, 재현율:0.5000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.7045, PR score : 0.6105\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.7\n",
      "오차행렬\n",
      "[[10  1]\n",
      " [ 4  4]]\n",
      "정확도: 0.7368, 정밀도 : 0.8000, 재현율:0.5000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.7045, PR score : 0.6105\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.8\n",
      "오차행렬\n",
      "[[10  1]\n",
      " [ 4  4]]\n",
      "정확도: 0.7368, 정밀도 : 0.8000, 재현율:0.5000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.7045, PR score : 0.6105\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "lda_pred = dt.predict(X_val)\n",
    "lda_pred_proba = dt.predict_proba(X_val)\n",
    "\n",
    "get_clf_eval(y_val, lda_pred)\n",
    "get_eval_by_threshold(y_val , lda_pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[11  0]\n",
      " [ 7  1]]\n",
      "정확도: 0.6316, 정밀도 : 1.0000, 재현율:0.1250,F1 스코어:0.2222\n",
      "ROC 스코어: 0.5625, PR score : 0.4934\n",
      "임곗값: 0.1\n",
      "오차행렬\n",
      "[[ 1 10]\n",
      " [ 0  8]]\n",
      "정확도: 0.4737, 정밀도 : 0.4444, 재현율:1.0000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.5455, PR score : 0.4444\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.2\n",
      "오차행렬\n",
      "[[3 8]\n",
      " [0 8]]\n",
      "정확도: 0.5789, 정밀도 : 0.5000, 재현율:1.0000,F1 스코어:0.6667\n",
      "ROC 스코어: 0.6364, PR score : 0.5000\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.3\n",
      "오차행렬\n",
      "[[8 3]\n",
      " [1 7]]\n",
      "정확도: 0.7895, 정밀도 : 0.7000, 재현율:0.8750,F1 스코어:0.7778\n",
      "ROC 스코어: 0.8011, PR score : 0.6651\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.4\n",
      "오차행렬\n",
      "[[9 2]\n",
      " [5 3]]\n",
      "정확도: 0.6316, 정밀도 : 0.6000, 재현율:0.3750,F1 스코어:0.4615\n",
      "ROC 스코어: 0.5966, PR score : 0.4882\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.5\n",
      "오차행렬\n",
      "[[11  0]\n",
      " [ 7  1]]\n",
      "정확도: 0.6316, 정밀도 : 1.0000, 재현율:0.1250,F1 스코어:0.2222\n",
      "ROC 스코어: 0.5625, PR score : 0.4934\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.6\n",
      "오차행렬\n",
      "[[11  0]\n",
      " [ 8  0]]\n",
      "정확도: 0.5789, 정밀도 : 0.0000, 재현율:0.0000,F1 스코어:0.0000\n",
      "ROC 스코어: 0.5000, PR score : 0.4211\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.7\n",
      "오차행렬\n",
      "[[11  0]\n",
      " [ 8  0]]\n",
      "정확도: 0.5789, 정밀도 : 0.0000, 재현율:0.0000,F1 스코어:0.0000\n",
      "ROC 스코어: 0.5000, PR score : 0.4211\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.8\n",
      "오차행렬\n",
      "[[11  0]\n",
      " [ 8  0]]\n",
      "정확도: 0.5789, 정밀도 : 0.0000, 재현율:0.0000,F1 스코어:0.0000\n",
      "ROC 스코어: 0.5000, PR score : 0.4211\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "lda_pred = rf.predict(X_val)\n",
    "lda_pred_proba = rf.predict_proba(X_val)\n",
    "\n",
    "get_clf_eval(y_val, lda_pred)\n",
    "get_eval_by_threshold(y_val , lda_pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 88, number of negative: 86\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 560\n",
      "[LightGBM] [Info] Number of data points in the train set: 174, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505747 -> initscore=0.022990\n",
      "[LightGBM] [Info] Start training from score 0.022990\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "오차행렬\n",
      "[[8 3]\n",
      " [4 4]]\n",
      "정확도: 0.6316, 정밀도 : 0.5714, 재현율:0.5000,F1 스코어:0.5333\n",
      "ROC 스코어: 0.6136, PR score : 0.4962\n",
      "임곗값: 0.1\n",
      "오차행렬\n",
      "[[3 8]\n",
      " [0 8]]\n",
      "정확도: 0.5789, 정밀도 : 0.5000, 재현율:1.0000,F1 스코어:0.6667\n",
      "ROC 스코어: 0.6364, PR score : 0.5000\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.2\n",
      "오차행렬\n",
      "[[5 6]\n",
      " [1 7]]\n",
      "정확도: 0.6316, 정밀도 : 0.5385, 재현율:0.8750,F1 스코어:0.6667\n",
      "ROC 스코어: 0.6648, PR score : 0.5238\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.3\n",
      "오차행렬\n",
      "[[6 5]\n",
      " [2 6]]\n",
      "정확도: 0.6316, 정밀도 : 0.5455, 재현율:0.7500,F1 스코어:0.6316\n",
      "ROC 스코어: 0.6477, PR score : 0.5144\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.4\n",
      "오차행렬\n",
      "[[7 4]\n",
      " [4 4]]\n",
      "정확도: 0.5789, 정밀도 : 0.5000, 재현율:0.5000,F1 스코어:0.5000\n",
      "ROC 스코어: 0.5682, PR score : 0.4605\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.5\n",
      "오차행렬\n",
      "[[8 3]\n",
      " [4 4]]\n",
      "정확도: 0.6316, 정밀도 : 0.5714, 재현율:0.5000,F1 스코어:0.5333\n",
      "ROC 스코어: 0.6136, PR score : 0.4962\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.6\n",
      "오차행렬\n",
      "[[8 3]\n",
      " [4 4]]\n",
      "정확도: 0.6316, 정밀도 : 0.5714, 재현율:0.5000,F1 스코어:0.5333\n",
      "ROC 스코어: 0.6136, PR score : 0.4962\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.7\n",
      "오차행렬\n",
      "[[8 3]\n",
      " [5 3]]\n",
      "정확도: 0.5789, 정밀도 : 0.5000, 재현율:0.3750,F1 스코어:0.4286\n",
      "ROC 스코어: 0.5511, PR score : 0.4507\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.8\n",
      "오차행렬\n",
      "[[10  1]\n",
      " [ 7  1]]\n",
      "정확도: 0.5789, 정밀도 : 0.5000, 재현율:0.1250,F1 스코어:0.2000\n",
      "ROC 스코어: 0.5170, PR score : 0.4309\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ada = ADASYN(sampling_strategy='minority', random_state=42)\n",
    "X_train, y_train = ada.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)\n",
    "lda_pred = lgbm.predict(X_val)\n",
    "lda_pred_proba = lgbm.predict_proba(X_val)\n",
    "\n",
    "get_clf_eval(y_val, lda_pred)\n",
    "get_eval_by_threshold(y_val , lda_pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11084044, 0.09555019, 0.067153  , 0.09432301, 0.10092416,\n",
       "       0.13157824, 0.09894149, 0.11343923, 0.09194081, 0.09530943])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['이론베이시스', '원위안 야간변동율', 'NAS 당일변동율', 'PUT_vol_change(%)', 'S&P 야간변동율',\n",
       "       'S&P 당일변화량', 'VIX 당일변동율', 'VIX 당일변화량', 'JNIV 종가변동율', 'JNIV 전날변화량'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이론베이시스</th>\n",
       "      <th>원위안 야간변동율</th>\n",
       "      <th>NAS 당일변동율</th>\n",
       "      <th>PUT_vol_change(%)</th>\n",
       "      <th>S&amp;P 야간변동율</th>\n",
       "      <th>S&amp;P 당일변화량</th>\n",
       "      <th>VIX 당일변동율</th>\n",
       "      <th>VIX 당일변화량</th>\n",
       "      <th>JNIV 종가변동율</th>\n",
       "      <th>JNIV 전날변화량</th>\n",
       "      <th>VKOSPI_Label</th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>0.847893</td>\n",
       "      <td>0.301805</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.640695</td>\n",
       "      <td>0.096850</td>\n",
       "      <td>0.574648</td>\n",
       "      <td>-0.050357</td>\n",
       "      <td>0.226852</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.718232</td>\n",
       "      <td>0.680202</td>\n",
       "      <td>0.703172</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.465170</td>\n",
       "      <td>0.321411</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.246435</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.802239</td>\n",
       "      <td>0.629834</td>\n",
       "      <td>0.652766</td>\n",
       "      <td>0.541234</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.283852</td>\n",
       "      <td>0.270016</td>\n",
       "      <td>0.476056</td>\n",
       "      <td>0.460784</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.353591</td>\n",
       "      <td>0.429763</td>\n",
       "      <td>0.403646</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.676611</td>\n",
       "      <td>0.623604</td>\n",
       "      <td>0.743662</td>\n",
       "      <td>0.237077</td>\n",
       "      <td>0.273148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.563536</td>\n",
       "      <td>0.254829</td>\n",
       "      <td>-0.024296</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.744823</td>\n",
       "      <td>1.145295</td>\n",
       "      <td>1.205634</td>\n",
       "      <td>0.327986</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.735075</td>\n",
       "      <td>0.265193</td>\n",
       "      <td>0.773924</td>\n",
       "      <td>0.694022</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.394786</td>\n",
       "      <td>0.077791</td>\n",
       "      <td>0.684507</td>\n",
       "      <td>0.388146</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.535912</td>\n",
       "      <td>0.773924</td>\n",
       "      <td>0.479667</td>\n",
       "      <td>0.452778</td>\n",
       "      <td>0.613034</td>\n",
       "      <td>0.579984</td>\n",
       "      <td>0.442254</td>\n",
       "      <td>0.523173</td>\n",
       "      <td>0.134259</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.720149</td>\n",
       "      <td>0.801105</td>\n",
       "      <td>0.382792</td>\n",
       "      <td>0.258683</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.675742</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.639437</td>\n",
       "      <td>0.173351</td>\n",
       "      <td>0.199074</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.651934</td>\n",
       "      <td>0.310360</td>\n",
       "      <td>0.505846</td>\n",
       "      <td>0.219444</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>0.809809</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.712707</td>\n",
       "      <td>0.297410</td>\n",
       "      <td>0.525578</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.576828</td>\n",
       "      <td>0.494498</td>\n",
       "      <td>0.397183</td>\n",
       "      <td>0.637701</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.630597</td>\n",
       "      <td>0.745856</td>\n",
       "      <td>0.736172</td>\n",
       "      <td>0.195331</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.766401</td>\n",
       "      <td>0.205662</td>\n",
       "      <td>1.014085</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.623134</td>\n",
       "      <td>0.359116</td>\n",
       "      <td>0.679543</td>\n",
       "      <td>0.780325</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.380159</td>\n",
       "      <td>0.261324</td>\n",
       "      <td>0.447887</td>\n",
       "      <td>0.387255</td>\n",
       "      <td>0.634259</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.608209</td>\n",
       "      <td>0.353591</td>\n",
       "      <td>0.219491</td>\n",
       "      <td>0.207098</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.540188</td>\n",
       "      <td>0.636842</td>\n",
       "      <td>0.670423</td>\n",
       "      <td>0.142157</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.578358</td>\n",
       "      <td>0.535912</td>\n",
       "      <td>0.289508</td>\n",
       "      <td>0.653367</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>0.608255</td>\n",
       "      <td>0.270933</td>\n",
       "      <td>0.490141</td>\n",
       "      <td>0.238859</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>1.011050</td>\n",
       "      <td>0.456980</td>\n",
       "      <td>0.257981</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.567994</td>\n",
       "      <td>0.644418</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.533582</td>\n",
       "      <td>0.475138</td>\n",
       "      <td>0.654741</td>\n",
       "      <td>0.406644</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.446488</td>\n",
       "      <td>0.211922</td>\n",
       "      <td>0.453521</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>0.143519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.514925</td>\n",
       "      <td>0.414365</td>\n",
       "      <td>0.698420</td>\n",
       "      <td>0.579078</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.416075</td>\n",
       "      <td>0.126994</td>\n",
       "      <td>0.532394</td>\n",
       "      <td>0.546791</td>\n",
       "      <td>0.634259</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.563536</td>\n",
       "      <td>0.884548</td>\n",
       "      <td>0.295648</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.495293</td>\n",
       "      <td>0.217863</td>\n",
       "      <td>0.504225</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.419890</td>\n",
       "      <td>0.693152</td>\n",
       "      <td>0.463046</td>\n",
       "      <td>0.980556</td>\n",
       "      <td>0.546850</td>\n",
       "      <td>0.248804</td>\n",
       "      <td>0.292958</td>\n",
       "      <td>0.105169</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      이론베이시스  원위안 야간변동율  NAS 당일변동율  PUT_vol_change(%)  S&P 야간변동율  S&P 당일변화량  \\\n",
       "0   0.850746   0.502762   0.847893           0.301805   0.630556   0.640695   \n",
       "1   0.798507   0.718232   0.680202           0.703172   0.600000   0.465170   \n",
       "2   0.802239   0.629834   0.652766           0.541234   0.575000   0.283852   \n",
       "3   0.798507   0.353591   0.429763           0.403646   0.283333   0.676611   \n",
       "4   0.776119   0.563536   0.254829          -0.024296   0.316667   0.744823   \n",
       "5   0.735075   0.265193   0.773924           0.694022   0.750000   0.394786   \n",
       "6   0.731343   0.535912   0.773924           0.479667   0.452778   0.613034   \n",
       "7   0.720149   0.801105   0.382792           0.258683   0.083333   0.675742   \n",
       "8   0.694030   0.651934   0.310360           0.505846   0.219444   0.813179   \n",
       "9   0.671642   0.712707   0.297410           0.525578   0.105556   0.576828   \n",
       "10  0.630597   0.745856   0.736172           0.195331   0.408333   0.766401   \n",
       "11  0.623134   0.359116   0.679543           0.780325   0.658333   0.380159   \n",
       "12  0.608209   0.353591   0.219491           0.207098   0.058333   0.540188   \n",
       "13  0.578358   0.535912   0.289508           0.653367   0.127778   0.608255   \n",
       "14  0.567164   1.011050   0.456980           0.257981   0.322222   0.567994   \n",
       "15  0.533582   0.475138   0.654741           0.406644   0.788889   0.446488   \n",
       "16  0.514925   0.414365   0.698420           0.579078   0.636111   0.416075   \n",
       "17  0.507463   0.563536   0.884548           0.295648   0.747222   0.495293   \n",
       "18  0.507463   0.419890   0.693152           0.463046   0.980556   0.546850   \n",
       "\n",
       "    VIX 당일변동율  VIX 당일변화량  JNIV 종가변동율  JNIV 전날변화량  VKOSPI_Label  pre  \n",
       "0    0.096850   0.574648   -0.050357    0.226852             1  1.0  \n",
       "1    0.321411   0.380282    0.246435    0.300926             0  0.0  \n",
       "2    0.270016   0.476056    0.460784    0.194444             0  1.0  \n",
       "3    0.623604   0.743662    0.237077    0.273148             0  0.0  \n",
       "4    1.145295   1.205634    0.327986    0.305556             1  0.0  \n",
       "5    0.077791   0.684507    0.388146    0.425926             0  1.0  \n",
       "6    0.579984   0.442254    0.523173    0.134259             0  0.0  \n",
       "7    0.659091   0.639437    0.173351    0.199074             1  1.0  \n",
       "8    0.809809   0.802817    0.294118    0.194444             1  0.0  \n",
       "9    0.494498   0.397183    0.637701    0.305556             0  0.0  \n",
       "10   0.205662   1.014085    0.470588    0.138889             0  0.0  \n",
       "11   0.261324   0.447887    0.387255    0.634259             1  1.0  \n",
       "12   0.636842   0.670423    0.142157    0.148148             1  1.0  \n",
       "13   0.270933   0.490141    0.238859    0.375000             1  0.0  \n",
       "14   0.644418   0.661972    0.704545    0.305556             0  0.0  \n",
       "15   0.211922   0.453521    0.065508    0.143519             1  0.0  \n",
       "16   0.126994   0.532394    0.546791    0.634259             0  1.0  \n",
       "17   0.217863   0.504225    0.009804    0.046296             0  0.0  \n",
       "18   0.248804   0.292958    0.105169    0.078704             0  0.0  "
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.concat([X_val,y_val],axis=1)\n",
    "a[\"pre\"] = lda_pred\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이론베이시스</th>\n",
       "      <th>원위안 야간변동율</th>\n",
       "      <th>NAS 당일변동율</th>\n",
       "      <th>PUT_vol_change(%)</th>\n",
       "      <th>S&amp;P 야간변동율</th>\n",
       "      <th>S&amp;P 당일변화량</th>\n",
       "      <th>VIX 당일변동율</th>\n",
       "      <th>VIX 당일변화량</th>\n",
       "      <th>JNIV 종가변동율</th>\n",
       "      <th>JNIV 전날변화량</th>\n",
       "      <th>VKOSPI_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.320442</td>\n",
       "      <td>0.861282</td>\n",
       "      <td>0.449257</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.344388</td>\n",
       "      <td>0.472329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351159</td>\n",
       "      <td>0.087963</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682836</td>\n",
       "      <td>0.348066</td>\n",
       "      <td>0.787752</td>\n",
       "      <td>0.544549</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.336713</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.315493</td>\n",
       "      <td>0.220143</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.314917</td>\n",
       "      <td>0.499781</td>\n",
       "      <td>0.543905</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.115134</td>\n",
       "      <td>0.476515</td>\n",
       "      <td>0.202817</td>\n",
       "      <td>0.284759</td>\n",
       "      <td>0.217593</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.458564</td>\n",
       "      <td>0.258560</td>\n",
       "      <td>0.418294</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.488487</td>\n",
       "      <td>0.412679</td>\n",
       "      <td>0.487324</td>\n",
       "      <td>0.263369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.436464</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>0.416851</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.538161</td>\n",
       "      <td>0.254226</td>\n",
       "      <td>0.363380</td>\n",
       "      <td>0.291444</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.771247</td>\n",
       "      <td>0.617254</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>0.200343</td>\n",
       "      <td>0.523380</td>\n",
       "      <td>0.241147</td>\n",
       "      <td>0.377325</td>\n",
       "      <td>0.359235</td>\n",
       "      <td>0.219264</td>\n",
       "      <td>0.194830</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.918138</td>\n",
       "      <td>0.511225</td>\n",
       "      <td>0.313597</td>\n",
       "      <td>0.472457</td>\n",
       "      <td>0.081976</td>\n",
       "      <td>0.755361</td>\n",
       "      <td>0.904869</td>\n",
       "      <td>0.853679</td>\n",
       "      <td>0.389199</td>\n",
       "      <td>0.273949</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.842268</td>\n",
       "      <td>0.386821</td>\n",
       "      <td>0.714451</td>\n",
       "      <td>0.356468</td>\n",
       "      <td>0.652818</td>\n",
       "      <td>0.364402</td>\n",
       "      <td>0.320172</td>\n",
       "      <td>0.332969</td>\n",
       "      <td>0.558209</td>\n",
       "      <td>0.335611</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.607713</td>\n",
       "      <td>0.575252</td>\n",
       "      <td>0.586285</td>\n",
       "      <td>0.385632</td>\n",
       "      <td>0.418053</td>\n",
       "      <td>0.246607</td>\n",
       "      <td>0.459696</td>\n",
       "      <td>0.528868</td>\n",
       "      <td>0.276162</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.557010</td>\n",
       "      <td>0.574858</td>\n",
       "      <td>0.517138</td>\n",
       "      <td>0.394499</td>\n",
       "      <td>0.412939</td>\n",
       "      <td>0.295721</td>\n",
       "      <td>0.436655</td>\n",
       "      <td>0.617242</td>\n",
       "      <td>0.263231</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       이론베이시스  원위안 야간변동율  NAS 당일변동율  PUT_vol_change(%)  S&P 야간변동율  S&P 당일변화량  \\\n",
       "0    0.723881   0.320442   0.861282           0.449257   0.555556   0.344388   \n",
       "1    0.682836   0.348066   0.787752           0.544549   0.483333   0.336713   \n",
       "2    0.671642   0.314917   0.499781           0.543905   0.455556   0.115134   \n",
       "3    0.656716   0.458564   0.258560           0.418294   0.341667   0.488487   \n",
       "4    0.641791   0.436464   0.896400           0.416851   0.825000   0.538161   \n",
       "..        ...        ...        ...                ...        ...        ...   \n",
       "169  0.771247   0.617254   0.705036           0.200343   0.523380   0.241147   \n",
       "170  0.918138   0.511225   0.313597           0.472457   0.081976   0.755361   \n",
       "171  0.842268   0.386821   0.714451           0.356468   0.652818   0.364402   \n",
       "172  0.865672   0.607713   0.575252           0.586285   0.385632   0.418053   \n",
       "173  0.865672   0.557010   0.574858           0.517138   0.394499   0.412939   \n",
       "\n",
       "     VIX 당일변동율  VIX 당일변화량  JNIV 종가변동율  JNIV 전날변화량  VKOSPI_Label  \n",
       "0     0.472329   0.000000    0.351159    0.087963           1.0  \n",
       "1     0.385965   0.315493    0.220143    0.092593           0.0  \n",
       "2     0.476515   0.202817    0.284759    0.217593           1.0  \n",
       "3     0.412679   0.487324    0.263369    0.000000           0.0  \n",
       "4     0.254226   0.363380    0.291444    0.175926           0.0  \n",
       "..         ...        ...         ...         ...           ...  \n",
       "169   0.377325   0.359235    0.219264    0.194830           1.0  \n",
       "170   0.904869   0.853679    0.389199    0.273949           1.0  \n",
       "171   0.320172   0.332969    0.558209    0.335611           1.0  \n",
       "172   0.246607   0.459696    0.528868    0.276162           1.0  \n",
       "173   0.295721   0.436655    0.617242    0.263231           1.0  \n",
       "\n",
       "[174 rows x 11 columns]"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pd.concat([X_train,y_train],axis=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이론베이시스</th>\n",
       "      <th>원위안 야간변동율</th>\n",
       "      <th>NAS 당일변동율</th>\n",
       "      <th>PUT_vol_change(%)</th>\n",
       "      <th>S&amp;P 야간변동율</th>\n",
       "      <th>S&amp;P 당일변화량</th>\n",
       "      <th>VIX 당일변동율</th>\n",
       "      <th>VIX 당일변화량</th>\n",
       "      <th>JNIV 종가변동율</th>\n",
       "      <th>JNIV 전날변화량</th>\n",
       "      <th>VKOSPI_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.483556</td>\n",
       "      <td>0.467622</td>\n",
       "      <td>0.600080</td>\n",
       "      <td>0.421633</td>\n",
       "      <td>0.493637</td>\n",
       "      <td>0.375033</td>\n",
       "      <td>0.411093</td>\n",
       "      <td>0.335113</td>\n",
       "      <td>0.324187</td>\n",
       "      <td>0.274009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.281673</td>\n",
       "      <td>0.174810</td>\n",
       "      <td>0.196084</td>\n",
       "      <td>0.171037</td>\n",
       "      <td>0.206104</td>\n",
       "      <td>0.224809</td>\n",
       "      <td>0.174778</td>\n",
       "      <td>0.169723</td>\n",
       "      <td>0.171738</td>\n",
       "      <td>0.227205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.242537</td>\n",
       "      <td>0.343923</td>\n",
       "      <td>0.464991</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.356250</td>\n",
       "      <td>0.187581</td>\n",
       "      <td>0.302861</td>\n",
       "      <td>0.203521</td>\n",
       "      <td>0.219474</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.403315</td>\n",
       "      <td>0.601405</td>\n",
       "      <td>0.416191</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.321723</td>\n",
       "      <td>0.388337</td>\n",
       "      <td>0.316901</td>\n",
       "      <td>0.294786</td>\n",
       "      <td>0.201389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.600829</td>\n",
       "      <td>0.709998</td>\n",
       "      <td>0.522816</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.491528</td>\n",
       "      <td>0.508423</td>\n",
       "      <td>0.431690</td>\n",
       "      <td>0.415998</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          이론베이시스  원위안 야간변동율  NAS 당일변동율  PUT_vol_change(%)  S&P 야간변동율  \\\n",
       "count  86.000000  86.000000  86.000000          86.000000  86.000000   \n",
       "mean    0.483556   0.467622   0.600080           0.421633   0.493637   \n",
       "std     0.281673   0.174810   0.196084           0.171037   0.206104   \n",
       "min     0.000000   0.176796   0.000000           0.000000   0.000000   \n",
       "25%     0.242537   0.343923   0.464991           0.322700   0.356250   \n",
       "50%     0.511194   0.403315   0.601405           0.416191   0.479167   \n",
       "75%     0.716418   0.600829   0.709998           0.522816   0.638889   \n",
       "max     1.000000   1.000000   1.000000           1.000000   1.000000   \n",
       "\n",
       "       S&P 당일변화량  VIX 당일변동율  VIX 당일변화량  JNIV 종가변동율  JNIV 전날변화량  VKOSPI_Label  \n",
       "count  86.000000  86.000000  86.000000   86.000000   86.000000          86.0  \n",
       "mean    0.375033   0.411093   0.335113    0.324187    0.274009           0.0  \n",
       "std     0.224809   0.174778   0.169723    0.171738    0.227205           0.0  \n",
       "min     0.006807   0.000000   0.050704    0.000000    0.000000           0.0  \n",
       "25%     0.187581   0.302861   0.203521    0.219474    0.101852           0.0  \n",
       "50%     0.321723   0.388337   0.316901    0.294786    0.201389           0.0  \n",
       "75%     0.491528   0.508423   0.431690    0.415998    0.407407           0.0  \n",
       "max     1.000000   1.000000   0.828169    1.000000    1.000000           0.0  "
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[b[\"VKOSPI_Label\"]==0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이론베이시스</th>\n",
       "      <th>원위안 야간변동율</th>\n",
       "      <th>NAS 당일변동율</th>\n",
       "      <th>PUT_vol_change(%)</th>\n",
       "      <th>S&amp;P 야간변동율</th>\n",
       "      <th>S&amp;P 당일변화량</th>\n",
       "      <th>VIX 당일변동율</th>\n",
       "      <th>VIX 당일변화량</th>\n",
       "      <th>JNIV 종가변동율</th>\n",
       "      <th>JNIV 전날변화량</th>\n",
       "      <th>VKOSPI_Label</th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.660448</td>\n",
       "      <td>0.579106</td>\n",
       "      <td>0.643387</td>\n",
       "      <td>0.467128</td>\n",
       "      <td>0.532828</td>\n",
       "      <td>0.527536</td>\n",
       "      <td>0.346459</td>\n",
       "      <td>0.557234</td>\n",
       "      <td>0.393656</td>\n",
       "      <td>0.257997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.121047</td>\n",
       "      <td>0.214046</td>\n",
       "      <td>0.175465</td>\n",
       "      <td>0.167291</td>\n",
       "      <td>0.249323</td>\n",
       "      <td>0.136157</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.205096</td>\n",
       "      <td>0.219920</td>\n",
       "      <td>0.169372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.265193</td>\n",
       "      <td>0.297410</td>\n",
       "      <td>0.195331</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.283852</td>\n",
       "      <td>0.077791</td>\n",
       "      <td>0.292958</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.541045</td>\n",
       "      <td>0.417127</td>\n",
       "      <td>0.554873</td>\n",
       "      <td>0.349647</td>\n",
       "      <td>0.365278</td>\n",
       "      <td>0.440623</td>\n",
       "      <td>0.211762</td>\n",
       "      <td>0.419718</td>\n",
       "      <td>0.241756</td>\n",
       "      <td>0.136574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.563536</td>\n",
       "      <td>0.693152</td>\n",
       "      <td>0.479667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.546850</td>\n",
       "      <td>0.270016</td>\n",
       "      <td>0.504225</td>\n",
       "      <td>0.460784</td>\n",
       "      <td>0.273148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.766791</td>\n",
       "      <td>0.715470</td>\n",
       "      <td>0.755048</td>\n",
       "      <td>0.560156</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.594931</td>\n",
       "      <td>0.537241</td>\n",
       "      <td>0.673239</td>\n",
       "      <td>0.534982</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.802239</td>\n",
       "      <td>1.011050</td>\n",
       "      <td>0.884548</td>\n",
       "      <td>0.703172</td>\n",
       "      <td>0.980556</td>\n",
       "      <td>0.766401</td>\n",
       "      <td>0.644418</td>\n",
       "      <td>1.014085</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.634259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          이론베이시스  원위안 야간변동율  NAS 당일변동율  PUT_vol_change(%)  S&P 야간변동율  \\\n",
       "count  11.000000  11.000000  11.000000          11.000000  11.000000   \n",
       "mean    0.660448   0.579106   0.643387           0.467128   0.532828   \n",
       "std     0.121047   0.214046   0.175465           0.167291   0.249323   \n",
       "min     0.507463   0.265193   0.297410           0.195331   0.105556   \n",
       "25%     0.541045   0.417127   0.554873           0.349647   0.365278   \n",
       "50%     0.671642   0.563536   0.693152           0.479667   0.575000   \n",
       "75%     0.766791   0.715470   0.755048           0.560156   0.691667   \n",
       "max     0.802239   1.011050   0.884548           0.703172   0.980556   \n",
       "\n",
       "       S&P 당일변화량  VIX 당일변동율  VIX 당일변화량  JNIV 종가변동율  JNIV 전날변화량  VKOSPI_Label  \\\n",
       "count  11.000000  11.000000  11.000000   11.000000   11.000000          11.0   \n",
       "mean    0.527536   0.346459   0.557234    0.393656    0.257997           0.0   \n",
       "std     0.136157   0.203655   0.205096    0.219920    0.169372           0.0   \n",
       "min     0.283852   0.077791   0.292958    0.009804    0.046296           0.0   \n",
       "25%     0.440623   0.211762   0.419718    0.241756    0.136574           0.0   \n",
       "50%     0.546850   0.270016   0.504225    0.460784    0.273148           0.0   \n",
       "75%     0.594931   0.537241   0.673239    0.534982    0.305556           0.0   \n",
       "max     0.766401   0.644418   1.014085    0.704545    0.634259           0.0   \n",
       "\n",
       "             pre  \n",
       "count  11.000000  \n",
       "mean    0.272727  \n",
       "std     0.467099  \n",
       "min     0.000000  \n",
       "25%     0.000000  \n",
       "50%     0.000000  \n",
       "75%     0.500000  \n",
       "max     1.000000  "
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a[\"VKOSPI_Label\"]==0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이론베이시스</th>\n",
       "      <th>원위안 야간변동율</th>\n",
       "      <th>NAS 당일변동율</th>\n",
       "      <th>PUT_vol_change(%)</th>\n",
       "      <th>S&amp;P 야간변동율</th>\n",
       "      <th>S&amp;P 당일변화량</th>\n",
       "      <th>VIX 당일변동율</th>\n",
       "      <th>VIX 당일변화량</th>\n",
       "      <th>JNIV 종가변동율</th>\n",
       "      <th>JNIV 전날변화량</th>\n",
       "      <th>VKOSPI_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.560963</td>\n",
       "      <td>0.414413</td>\n",
       "      <td>0.577828</td>\n",
       "      <td>0.398523</td>\n",
       "      <td>0.402560</td>\n",
       "      <td>0.317569</td>\n",
       "      <td>0.465392</td>\n",
       "      <td>0.359549</td>\n",
       "      <td>0.354741</td>\n",
       "      <td>0.231753</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.269281</td>\n",
       "      <td>0.110007</td>\n",
       "      <td>0.150341</td>\n",
       "      <td>0.140680</td>\n",
       "      <td>0.189007</td>\n",
       "      <td>0.182542</td>\n",
       "      <td>0.198032</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>0.143425</td>\n",
       "      <td>0.144879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201493</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.372201</td>\n",
       "      <td>0.357407</td>\n",
       "      <td>0.491893</td>\n",
       "      <td>0.315695</td>\n",
       "      <td>0.260687</td>\n",
       "      <td>0.207237</td>\n",
       "      <td>0.338780</td>\n",
       "      <td>0.193775</td>\n",
       "      <td>0.260250</td>\n",
       "      <td>0.127701</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.600145</td>\n",
       "      <td>0.386781</td>\n",
       "      <td>0.612417</td>\n",
       "      <td>0.382765</td>\n",
       "      <td>0.419528</td>\n",
       "      <td>0.266202</td>\n",
       "      <td>0.426749</td>\n",
       "      <td>0.349553</td>\n",
       "      <td>0.359885</td>\n",
       "      <td>0.201695</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.810657</td>\n",
       "      <td>0.453039</td>\n",
       "      <td>0.669897</td>\n",
       "      <td>0.489313</td>\n",
       "      <td>0.539519</td>\n",
       "      <td>0.430774</td>\n",
       "      <td>0.565817</td>\n",
       "      <td>0.459503</td>\n",
       "      <td>0.434548</td>\n",
       "      <td>0.283071</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>0.894425</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.786111</td>\n",
       "      <td>0.878783</td>\n",
       "      <td>0.913357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865865</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          이론베이시스  원위안 야간변동율  NAS 당일변동율  PUT_vol_change(%)  S&P 야간변동율  \\\n",
       "count  88.000000  88.000000  88.000000          88.000000  88.000000   \n",
       "mean    0.560963   0.414413   0.577828           0.398523   0.402560   \n",
       "std     0.269281   0.110007   0.150341           0.140680   0.189007   \n",
       "min     0.014925   0.000000   0.201493           0.056391   0.072222   \n",
       "25%     0.372201   0.357407   0.491893           0.315695   0.260687   \n",
       "50%     0.600145   0.386781   0.612417           0.382765   0.419528   \n",
       "75%     0.810657   0.453039   0.669897           0.489313   0.539519   \n",
       "max     0.985075   0.872928   0.894425           0.705376   0.786111   \n",
       "\n",
       "       S&P 당일변화량  VIX 당일변동율  VIX 당일변화량  JNIV 종가변동율  JNIV 전날변화량  VKOSPI_Label  \n",
       "count  88.000000  88.000000  88.000000   88.000000   88.000000          88.0  \n",
       "mean    0.317569   0.465392   0.359549    0.354741    0.231753           1.0  \n",
       "std     0.182542   0.198032   0.198164    0.143425    0.144879           0.0  \n",
       "min     0.000000   0.060526   0.000000    0.000000    0.046296           1.0  \n",
       "25%     0.207237   0.338780   0.193775    0.260250    0.127701           1.0  \n",
       "50%     0.266202   0.426749   0.349553    0.359885    0.201695           1.0  \n",
       "75%     0.430774   0.565817   0.459503    0.434548    0.283071           1.0  \n",
       "max     0.878783   0.913357   1.000000    0.865865    0.768519           1.0  "
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[b[\"VKOSPI_Label\"]==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이론베이시스</th>\n",
       "      <th>원위안 야간변동율</th>\n",
       "      <th>NAS 당일변동율</th>\n",
       "      <th>PUT_vol_change(%)</th>\n",
       "      <th>S&amp;P 야간변동율</th>\n",
       "      <th>S&amp;P 당일변화량</th>\n",
       "      <th>VIX 당일변동율</th>\n",
       "      <th>VIX 당일변화량</th>\n",
       "      <th>JNIV 종가변동율</th>\n",
       "      <th>JNIV 전날변화량</th>\n",
       "      <th>VKOSPI_Label</th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.673041</td>\n",
       "      <td>0.530387</td>\n",
       "      <td>0.454895</td>\n",
       "      <td>0.386184</td>\n",
       "      <td>0.360417</td>\n",
       "      <td>0.606191</td>\n",
       "      <td>0.511508</td>\n",
       "      <td>0.660563</td>\n",
       "      <td>0.197360</td>\n",
       "      <td>0.278356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.106885</td>\n",
       "      <td>0.148130</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>0.257852</td>\n",
       "      <td>0.290137</td>\n",
       "      <td>0.145919</td>\n",
       "      <td>0.360619</td>\n",
       "      <td>0.251397</td>\n",
       "      <td>0.144706</td>\n",
       "      <td>0.163821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.533582</td>\n",
       "      <td>0.353591</td>\n",
       "      <td>0.219491</td>\n",
       "      <td>-0.024296</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.380159</td>\n",
       "      <td>0.096850</td>\n",
       "      <td>0.447887</td>\n",
       "      <td>-0.050357</td>\n",
       "      <td>0.143519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.600746</td>\n",
       "      <td>0.446133</td>\n",
       "      <td>0.280838</td>\n",
       "      <td>0.245787</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.516763</td>\n",
       "      <td>0.248973</td>\n",
       "      <td>0.480986</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.182870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.658582</td>\n",
       "      <td>0.519337</td>\n",
       "      <td>0.346576</td>\n",
       "      <td>0.354225</td>\n",
       "      <td>0.268056</td>\n",
       "      <td>0.624475</td>\n",
       "      <td>0.453888</td>\n",
       "      <td>0.607042</td>\n",
       "      <td>0.206105</td>\n",
       "      <td>0.212963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.734142</td>\n",
       "      <td>0.585635</td>\n",
       "      <td>0.660942</td>\n",
       "      <td>0.542726</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.693012</td>\n",
       "      <td>0.696770</td>\n",
       "      <td>0.703521</td>\n",
       "      <td>0.302585</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.801105</td>\n",
       "      <td>0.847893</td>\n",
       "      <td>0.780325</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.813179</td>\n",
       "      <td>1.145295</td>\n",
       "      <td>1.205634</td>\n",
       "      <td>0.387255</td>\n",
       "      <td>0.634259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         이론베이시스  원위안 야간변동율  NAS 당일변동율  PUT_vol_change(%)  S&P 야간변동율  \\\n",
       "count  8.000000   8.000000   8.000000           8.000000   8.000000   \n",
       "mean   0.673041   0.530387   0.454895           0.386184   0.360417   \n",
       "std    0.106885   0.148130   0.237167           0.257852   0.290137   \n",
       "min    0.533582   0.353591   0.219491          -0.024296   0.058333   \n",
       "25%    0.600746   0.446133   0.280838           0.245787   0.116667   \n",
       "50%    0.658582   0.519337   0.346576           0.354225   0.268056   \n",
       "75%    0.734142   0.585635   0.660942           0.542726   0.637500   \n",
       "max    0.850746   0.801105   0.847893           0.780325   0.788889   \n",
       "\n",
       "       S&P 당일변화량  VIX 당일변동율  VIX 당일변화량  JNIV 종가변동율  JNIV 전날변화량  VKOSPI_Label  \\\n",
       "count   8.000000   8.000000   8.000000    8.000000    8.000000           8.0   \n",
       "mean    0.606191   0.511508   0.660563    0.197360    0.278356           1.0   \n",
       "std     0.145919   0.360619   0.251397    0.144706    0.163821           0.0   \n",
       "min     0.380159   0.096850   0.447887   -0.050357    0.143519           1.0   \n",
       "25%     0.516763   0.248973   0.480986    0.122995    0.182870           1.0   \n",
       "50%     0.624475   0.453888   0.607042    0.206105    0.212963           1.0   \n",
       "75%     0.693012   0.696770   0.703521    0.302585    0.322917           1.0   \n",
       "max     0.813179   1.145295   1.205634    0.387255    0.634259           1.0   \n",
       "\n",
       "            pre  \n",
       "count  8.000000  \n",
       "mean   0.500000  \n",
       "std    0.534522  \n",
       "min    0.000000  \n",
       "25%    0.000000  \n",
       "50%    0.500000  \n",
       "75%    1.000000  \n",
       "max    1.000000  "
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a[\"VKOSPI_Label\"]==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이론베이시스</th>\n",
       "      <th>원위안 야간변동율</th>\n",
       "      <th>NAS 당일변동율</th>\n",
       "      <th>PUT_vol_change(%)</th>\n",
       "      <th>S&amp;P 야간변동율</th>\n",
       "      <th>S&amp;P 당일변화량</th>\n",
       "      <th>VIX 당일변동율</th>\n",
       "      <th>VIX 당일변화량</th>\n",
       "      <th>JNIV 종가변동율</th>\n",
       "      <th>JNIV 전날변화량</th>\n",
       "      <th>VKOSPI_Label</th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.660448</td>\n",
       "      <td>0.579106</td>\n",
       "      <td>0.643387</td>\n",
       "      <td>0.467128</td>\n",
       "      <td>0.532828</td>\n",
       "      <td>0.527536</td>\n",
       "      <td>0.346459</td>\n",
       "      <td>0.557234</td>\n",
       "      <td>0.393656</td>\n",
       "      <td>0.257997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.121047</td>\n",
       "      <td>0.214046</td>\n",
       "      <td>0.175465</td>\n",
       "      <td>0.167291</td>\n",
       "      <td>0.249323</td>\n",
       "      <td>0.136157</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.205096</td>\n",
       "      <td>0.219920</td>\n",
       "      <td>0.169372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.265193</td>\n",
       "      <td>0.297410</td>\n",
       "      <td>0.195331</td>\n",
       "      <td>0.105556</td>\n",
       "      <td>0.283852</td>\n",
       "      <td>0.077791</td>\n",
       "      <td>0.292958</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.541045</td>\n",
       "      <td>0.417127</td>\n",
       "      <td>0.554873</td>\n",
       "      <td>0.349647</td>\n",
       "      <td>0.365278</td>\n",
       "      <td>0.440623</td>\n",
       "      <td>0.211762</td>\n",
       "      <td>0.419718</td>\n",
       "      <td>0.241756</td>\n",
       "      <td>0.136574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.563536</td>\n",
       "      <td>0.693152</td>\n",
       "      <td>0.479667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.546850</td>\n",
       "      <td>0.270016</td>\n",
       "      <td>0.504225</td>\n",
       "      <td>0.460784</td>\n",
       "      <td>0.273148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.766791</td>\n",
       "      <td>0.715470</td>\n",
       "      <td>0.755048</td>\n",
       "      <td>0.560156</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.594931</td>\n",
       "      <td>0.537241</td>\n",
       "      <td>0.673239</td>\n",
       "      <td>0.534982</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.802239</td>\n",
       "      <td>1.011050</td>\n",
       "      <td>0.884548</td>\n",
       "      <td>0.703172</td>\n",
       "      <td>0.980556</td>\n",
       "      <td>0.766401</td>\n",
       "      <td>0.644418</td>\n",
       "      <td>1.014085</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.634259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          이론베이시스  원위안 야간변동율  NAS 당일변동율  PUT_vol_change(%)  S&P 야간변동율  \\\n",
       "count  11.000000  11.000000  11.000000          11.000000  11.000000   \n",
       "mean    0.660448   0.579106   0.643387           0.467128   0.532828   \n",
       "std     0.121047   0.214046   0.175465           0.167291   0.249323   \n",
       "min     0.507463   0.265193   0.297410           0.195331   0.105556   \n",
       "25%     0.541045   0.417127   0.554873           0.349647   0.365278   \n",
       "50%     0.671642   0.563536   0.693152           0.479667   0.575000   \n",
       "75%     0.766791   0.715470   0.755048           0.560156   0.691667   \n",
       "max     0.802239   1.011050   0.884548           0.703172   0.980556   \n",
       "\n",
       "       S&P 당일변화량  VIX 당일변동율  VIX 당일변화량  JNIV 종가변동율  JNIV 전날변화량  VKOSPI_Label  \\\n",
       "count  11.000000  11.000000  11.000000   11.000000   11.000000          11.0   \n",
       "mean    0.527536   0.346459   0.557234    0.393656    0.257997           0.0   \n",
       "std     0.136157   0.203655   0.205096    0.219920    0.169372           0.0   \n",
       "min     0.283852   0.077791   0.292958    0.009804    0.046296           0.0   \n",
       "25%     0.440623   0.211762   0.419718    0.241756    0.136574           0.0   \n",
       "50%     0.546850   0.270016   0.504225    0.460784    0.273148           0.0   \n",
       "75%     0.594931   0.537241   0.673239    0.534982    0.305556           0.0   \n",
       "max     0.766401   0.644418   1.014085    0.704545    0.634259           0.0   \n",
       "\n",
       "             pre  \n",
       "count  11.000000  \n",
       "mean    0.272727  \n",
       "std     0.467099  \n",
       "min     0.000000  \n",
       "25%     0.000000  \n",
       "50%     0.000000  \n",
       "75%     0.500000  \n",
       "max     1.000000  "
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a[\"VKOSPI_Label\"]==0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[6 5]\n",
      " [4 4]]\n",
      "정확도: 0.5263, 정밀도 : 0.4444, 재현율:0.5000,F1 스코어:0.4706\n",
      "ROC 스코어: 0.5227, PR score : 0.4327\n",
      "임곗값: 0.1\n",
      "오차행렬\n",
      "[[ 0 11]\n",
      " [ 0  8]]\n",
      "정확도: 0.4211, 정밀도 : 0.4211, 재현율:1.0000,F1 스코어:0.5926\n",
      "ROC 스코어: 0.5000, PR score : 0.4211\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.2\n",
      "오차행렬\n",
      "[[ 0 11]\n",
      " [ 0  8]]\n",
      "정확도: 0.4211, 정밀도 : 0.4211, 재현율:1.0000,F1 스코어:0.5926\n",
      "ROC 스코어: 0.5000, PR score : 0.4211\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.3\n",
      "오차행렬\n",
      "[[ 1 10]\n",
      " [ 0  8]]\n",
      "정확도: 0.4737, 정밀도 : 0.4444, 재현율:1.0000,F1 스코어:0.6154\n",
      "ROC 스코어: 0.5455, PR score : 0.4444\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.4\n",
      "오차행렬\n",
      "[[4 7]\n",
      " [3 5]]\n",
      "정확도: 0.4737, 정밀도 : 0.4167, 재현율:0.6250,F1 스코어:0.5000\n",
      "ROC 스코어: 0.4943, PR score : 0.4183\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.5\n",
      "오차행렬\n",
      "[[6 5]\n",
      " [4 4]]\n",
      "정확도: 0.5263, 정밀도 : 0.4444, 재현율:0.5000,F1 스코어:0.4706\n",
      "ROC 스코어: 0.5227, PR score : 0.4327\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.6\n",
      "오차행렬\n",
      "[[11  0]\n",
      " [ 6  2]]\n",
      "정확도: 0.6842, 정밀도 : 1.0000, 재현율:0.2500,F1 스코어:0.4000\n",
      "ROC 스코어: 0.6250, PR score : 0.5658\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.7\n",
      "오차행렬\n",
      "[[11  0]\n",
      " [ 8  0]]\n",
      "정확도: 0.5789, 정밀도 : 0.0000, 재현율:0.0000,F1 스코어:0.0000\n",
      "ROC 스코어: 0.5000, PR score : 0.4211\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.8\n",
      "오차행렬\n",
      "[[11  0]\n",
      " [ 8  0]]\n",
      "정확도: 0.5789, 정밀도 : 0.0000, 재현율:0.0000,F1 스코어:0.0000\n",
      "ROC 스코어: 0.5000, PR score : 0.4211\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "logit =   LogisticRegression()\n",
    "logit.fit(X_train, y_train)\n",
    "lda_pred = logit.predict(X_val)\n",
    "lda_pred_proba = logit.predict_proba(X_val)\n",
    "\n",
    "get_clf_eval(y_val, lda_pred)\n",
    "get_eval_by_threshold(y_val , lda_pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63213941, 0.36786059],\n",
       "       [0.66937655, 0.33062345],\n",
       "       [0.49817835, 0.50182165],\n",
       "       [0.4134767 , 0.5865233 ],\n",
       "       [0.31520322, 0.68479678],\n",
       "       [0.57165753, 0.42834247],\n",
       "       [0.46021837, 0.53978163],\n",
       "       [0.46556685, 0.53443315],\n",
       "       [0.49838335, 0.50161665],\n",
       "       [0.47140128, 0.52859872],\n",
       "       [0.49594587, 0.50405413],\n",
       "       [0.65226174, 0.34773826],\n",
       "       [0.33285093, 0.66714907],\n",
       "       [0.58498903, 0.41501097],\n",
       "       [0.51209992, 0.48790008],\n",
       "       [0.68407654, 0.31592346],\n",
       "       [0.63326775, 0.36673225],\n",
       "       [0.65620423, 0.34379577],\n",
       "       [0.75983056, 0.24016944]])"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
